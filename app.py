import streamlit as st
from PIL import Image
import os
import folium
from streamlit_folium import st_folium

# --- NOUVEAUX IMPORTS POUR LA FONCTIONNALIT√â CHATBOT ---
from groq import Groq
import base64
import tempfile

# --- NOUVEAUX IMPORTS POUR LA FONCTIONNALIT√â D'ANALYSE DE PLANTE ---
import tensorflow as tf
import numpy as np

# --- IMPORT POUR T√âL√âCHARGER LE MOD√àLE DE HUGGING FACE ---
from huggingface_hub import hf_hub_download

# --- CUSTOM AUDIO RECORDER COMPONENT PLACEHOLDER (conservez-le si n√©cessaire) ---
# Si vous utilisez un composant Streamlit personnalis√© pour l'enregistrement audio,
# assurez-vous que son dossier (audio_recorder_component) est bien √† la racine de votre projet
# et qu'il est correctement construit pour le d√©ploiement.
try:
    import streamlit.components.v1 as components
    _audio_recorder_component = components.declare_component(
        "audio_recorder_component",
        path="./audio_recorder_component/frontend/build"
    )
    def audio_recorder_component():
        return _audio_recorder_component(key="audio_recorder_widget")
except Exception as e:
    st.warning(f"Impossible de charger le composant d'enregistrement audio personnalis√©. La fonctionnalit√© d'enregistrement audio pourrait √™tre limit√©e : {e}")
    def audio_recorder_component():
        st.info("Le composant d'enregistrement audio n'a pas √©t√© charg√©. Veuillez vous assurer qu'il est correctement install√© et que FFmpeg/FFprobe sont disponibles, OU supprimez le code li√© si vous n'en avez pas besoin.")
        return None

# --- Configuration de la page Streamlit ---
st.set_page_config(
    page_title="GreenField Pro - Dashboard",
    page_icon=":seedling:",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Chemins des ressources statiques et du mod√®le ---
# Assurez-vous que le dossier 'static' est √† la racine de votre d√©p√¥t GitHub
LOGO_PATH = os.path.join("static", "images", "Green Plant and Agriculture Logo (2).png")
CSS_PATH = "style.css"

# --- CONFIGURATION DE VOTRE MOD√àLE HUGGING FACE ---
# C'est ici que l'ID de votre d√©p√¥t Hugging Face est utilis√©.
HF_MODEL_REPO_ID = "mopaoleonel/plante_tedection"
# Le nom exact du fichier de votre mod√®le tel qu'upload√© sur Hugging Face Hub
HF_MODEL_FILENAME = "mon_modele.keras"

# --- Dictionnaire des classes de maladies ---
CLASS_NAMES = {
    'Apple___Apple_scab': 0, 'Apple___Black_rot': 1, 'Apple___Cedar_apple_rust': 2, 'Apple___healthy': 3,
    'Blueberry___healthy': 4, 'Cherry_(including_sour)___Powdery_mildew': 5, 'Cherry_(including_sour)___healthy': 6,
    'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot': 7, 'Corn_(maize)___Common_rust_': 8, 'Corn_(maize)___Northern_Leaf_Blight': 9,
    'Corn_(maize)___healthy': 10, 'Grape___Black_rot': 11, 'Grape___Esca_(Black_Measles)': 12, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 13,
    'Grape___healthy': 14, 'Orange___Haunglongbing_(Citrus_greening)': 15, 'Peach___Bacterial_spot': 16, 'Peach___healthy': 17,
    'Pepper,_bell___Bacterial_spot': 18, 'Pepper,_bell___healthy': 19, 'Potato___Early_blight': 20, 'Potato___Late_blight': 21,
    'Potato___healthy': 22, 'Raspberry___healthy': 23, 'Soybean___healthy': 24, 'Squash___Powdery_mildew': 25,
    'Strawberry___Leaf_scorch': 26, 'Strawberry___healthy': 27, 'Tomato___Bacterial_spot': 28, 'Tomato___Early_blight': 29,
    'Tomato___Late_blight': 30, 'Tomato___Leaf_Mold': 31, 'Tomato___Septoria_leaf_spot': 32, 'Tomato___Spider_mites Two-spotted_spider_mite': 33,
    'Tomato___Target_Spot': 34, 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 35, 'Tomato___Tomato_mosaic_virus': 36, 'Tomato___healthy': 37
}
# Inverser le dictionnaire pour un acc√®s facile par index
CLASS_NAMES_INV = {v: k for k, v in CLASS_NAMES.items()}

# Taille d'entr√©e attendue par votre mod√®le
IMG_HEIGHT = 64
IMG_WIDTH = 64
IMG_CHANNELS = 3 # RGB

# --- Fonctions utilitaires et de chargement ---

def load_css(css_file):
    """Charge un fichier CSS externe."""
    try:
        with open(css_file) as f:
            st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
    except FileNotFoundError:
        st.warning(f"Fichier CSS non trouv√© √† : {css_file}. L'interface utilisera les styles par d√©faut.")
    except Exception as e:
        st.error(f"Erreur lors du chargement du CSS : {e}")

@st.cache_resource # Met en cache le mod√®le pour √©viter les rechargements co√ªteux
def load_keras_model_from_hub(repo_id, filename):
    """
    T√©l√©charge le mod√®le Keras depuis Hugging Face Hub et le charge.
    Utilise la m√©thode robuste de chargement/recompilation pour Streamlit Cloud.
    """
    try:
        with st.spinner(f"T√©l√©chargement du mod√®le '{filename}' depuis Hugging Face Hub..."):
            # T√©l√©charge le fichier du mod√®le dans le cache de l'application Streamlit
            # Cela retournera le chemin local o√π le fichier a √©t√© sauvegard√©.
            model_path = hf_hub_download(repo_id=repo_id, filename=filename)
            st.success(f"Mod√®le t√©l√©charg√© depuis Hugging Face Hub : {model_path}")

        # Tente de charger le mod√®le SANS compiler pour √©viter les erreurs d'optimiseur/version
        # 'custom_objects' peut √™tre n√©cessaire si votre mod√®le utilise des couches ou fonctions d'activation personnalis√©es.
        # Pour Keras 'mon_modele.keras', ce n'est g√©n√©ralement pas n√©cessaire si vous utilisez des couches standard.
        model = tf.keras.models.load_model(model_path, compile=False)

        # --- TR√àS IMPORTANT : RE-COMPILER LE MOD√àLE ---
        # Vous DEVEZ conna√Ætre l'optimiseur, la fonction de perte et les m√©triques
        # exacts utilis√©s lors de l'entra√Ænement de votre mod√®le 'mon_modele.keras'.
        # Ajustez les param√®tres ci-dessous en cons√©quence pour qu'ils correspondent √† l'entra√Ænement.
        # `from_logits=False` est pour les mod√®les avec softmax sur la derni√®re couche.
        # Si votre mod√®le sort des logits bruts (PAS de softmax), utilisez `from_logits=True`.
        model.compile(optimizer=tf.keras.optimizers.Adam(),
                        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
                        metrics=['accuracy'])

        st.success(f"Mod√®le Keras '{filename}' charg√© et recompil√© avec succ√®s !")
        return model
    except Exception as e:
        st.error(f"Erreur lors du t√©l√©chargement ou du chargement du mod√®le Keras depuis Hugging Face Hub : {e}.")
        st.info(f"Assurez-vous que l'ID du mod√®le '{repo_id}' et le nom de fichier '{filename}' sont corrects sur Hugging Face Hub, et que le fichier .keras est valide.")
        return None

# --- Fonctions pour les vues sp√©cifiques ---

def show_dashboard_view():
    st.markdown("<h1>Tableau de Bord</h1>", unsafe_allow_html=True)
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.markdown("""<a href="#" class="info-card"><div><div class="value">24¬∞C</div><div class="label">Temp√©rature</div></div><div class="icon-container"><i class="fas fa-thermometer-three-quarters"></i></div></a>""", unsafe_allow_html=True)
    with col2:
        st.markdown("""<a href="#" class="info-card"><div><div class="value">42.5%</div><div class="label">Humidit√©</div></div><div class="icon-container"><i class="fas fa-tint"></i></div></a>""", unsafe_allow_html=True)
    with col3:
        st.markdown("""<a href="#" class="info-card"><div><div class="value">3.0mm</div><div class="label">Pr√©cipitation</div></div><div class="icon-container"><i class="fas fa-cloud-rain"></i></div></a>""", unsafe_allow_html=True)
    with col4:
        st.markdown("""<a href="#" class="info-card"><div><div class="value">3.5m/s</div><div class="label">Vent</div></div><div class="icon-container"><i class="fas fa-wind"></i></div></a>""", unsafe_allow_html=True)
    st.markdown("---")
    st.markdown("<h2 id='map-plantation'><i class='fa-solid fa-map-location-dot'></i> Carte des Plantations</h2>", unsafe_allow_html=True)
    center_lat = 5.4746
    center_lon = 10.4243
    m = folium.Map(location=[center_lat, center_lon], zoom_start=10, control_scale=True)
    folium.Marker(location=[center_lat, center_lon],popup="<b>Bafoussam</b><br>Zone de Plantation Principale",tooltip="Bafoussam").add_to(m)
    folium.Marker(location=[5.62, 10.05],popup="<b>Zone Ouest</b><br>Quelques fermes ici.",icon=folium.Icon(color="green", icon="leaf")).add_to(m)
    st_folium(m, width='100%', height=500)
    st.markdown("""<p style='color: var(--text-color); margin-top: 1rem;'>Visualisation des emplacements de vos plantations et des points d'int√©r√™t.</p>""", unsafe_allow_html=True)


def show_plant_analysis_view(groq_client, model):
    st.markdown("<h2 id='analyse-plant'><i class='fa-solid fa-microscope'></i> Analyser ma plante</h2>", unsafe_allow_html=True)
    st.markdown("T√©l√©chargez une image de la feuille de votre plante pour obtenir un diagnostic instantan√© et des recommandations.")

    if not model:
        st.error("Le service d'analyse est indisponible car le mod√®le de pr√©diction n'a pas pu √™tre charg√©. Veuillez v√©rifier le chemin du mod√®le et les configurations.")
        return

    uploaded_file = st.file_uploader("Choisissez une image...", type=["jpg", "jpeg", "png"], label_visibility="collapsed", key="plant_analysis_uploader")

    if uploaded_file is not None:
        col1, col2 = st.columns([0.8, 1.2])
        with col1:
            st.image(uploaded_file, caption="Image t√©l√©charg√©e", use_container_width=True)

        with col2:
            with st.spinner("Analyse de l'image en cours..."):
                try:
                    image = Image.open(uploaded_file).convert('RGB')
                    img_resized = image.resize((IMG_WIDTH, IMG_HEIGHT))
                    img_array = tf.keras.preprocessing.image.img_to_array(img_resized)
                    img_array = tf.expand_dims(img_array, 0)
                    img_array = tf.cast(img_array, tf.float32) / 255.0

                    prediction = model.predict(img_array)
                    predicted_class_index = np.argmax(prediction)
                    predicted_class_name = CLASS_NAMES_INV[predicted_class_index]
                    
                    parts = predicted_class_name.split('___')
                    plant_name = parts[0].replace('_', ' ')
                    disease_name = parts[1].replace('_', ' ')
                    
                except Exception as e:
                    st.error(f"Erreur lors du traitement de l'image ou de la pr√©diction : {e}")
                    st.info("Assurez-vous que l'image est valide et que le mod√®le est compatible.")
                    return

            st.subheader("R√©sultats de l'analyse")
            if 'healthy' in disease_name.lower():
                st.success(f"**Diagnostic :** La plante ({plant_name}) semble **saine**.")
                st.balloons()
                st.markdown("<hr>", unsafe_allow_html=True)
                st.subheader("Conseils pour une plante saine")
                if not groq_client:
                    st.info("Le service de conseils est indisponible car la cl√© API Groq n'a pas √©t√© configur√©e.")
                    st.markdown("<p style='font-style: italic; color: #888;'>Veuillez configurer votre cl√© API Groq pour obtenir des conseils d√©taill√©s.</p>", unsafe_allow_html=True)
                else:
                    with st.spinner(f"G√©n√©ration de conseils pour maintenir {plant_name} saine..."):
                        try:
                            prompt = f"""
                            Je suis un agriculteur. Mon application a diagnostiqu√© que ma plante '{plant_name}' est saine.
                            Donne-moi des conseils pratiques et concis pour maintenir la bonne sant√© de cette plante.
                            Structure ta r√©ponse comme suit en Markdown :

                            ### üå± Conseils pour une Plante Saine
                            - [Conseil 1]
                            - [Conseil 2]
                            - [Etc...]

                            Ajoute une petite conclusion encourageante.
                            """
                            chat_completion = groq_client.chat.completions.create(messages=[{"role": "user", "content": prompt}], model="llama3-70b-8192")
                            response_text = chat_completion.choices[0].message.content
                            st.markdown(response_text)
                        except Exception as e:
                            st.error(f"Impossible de g√©n√©rer les conseils. Erreur API Groq : {e}. Veuillez v√©rifier votre connexion et votre cl√© API.")

            else:
                st.warning(f"**Diagnostic :** {plant_name} - **{disease_name}**")
                
                if not groq_client:
                    st.info("Le service de recommandation est indisponible car la cl√© API Groq n'a pas √©t√© configur√©e.")
                    st.markdown("<p style='font-style: italic; color: #888;'>Veuillez configurer votre cl√© API Groq pour obtenir des recommandations d√©taill√©es.</p>", unsafe_allow_html=True)
                else:
                    st.markdown("<hr>", unsafe_allow_html=True)
                    with st.spinner(f"Recherche des causes et solutions pour '{disease_name}'..."):
                        try:
                            prompt = f"""
                            Je suis un agriculteur et mon application a diagnostiqu√© la maladie '{disease_name}' sur ma plante '{plant_name}'.
                            Fournis-moi une fiche d'information claire et concise en fran√ßais sur cette maladie. Structure ta r√©ponse exactement comme suit, en utilisant Markdown :

                            ### üßê Causes Principales
                            - [Cause 1]
                            - [Cause 2]
                            - [Etc...]

                            ### üõ°Ô∏è Solutions et Traitements
                            **Pr√©vention :**
                            - [Mesure pr√©ventive 1]
                            - [Mesure pr√©ventive 2]
                            **Traitements Biologiques :**
                            - [Traitement biologique 1]
                            **Traitements Chimiques :**
                            - [Traitement chimique 1]
                            
                            Ajoute √† la fin une petite conclusion encourageante.
                            """
                            chat_completion = groq_client.chat.completions.create(messages=[{"role": "user", "content": prompt}], model="llama3-70b-8192")
                            response_text = chat_completion.choices[0].message.content
                            st.markdown(response_text)
                        except Exception as e:
                            st.error(f"Impossible de g√©n√©rer les recommandations. Erreur API Groq : {e}. Veuillez v√©rifier votre connexion et votre cl√© API.")


def show_chatbot_view(groq_client):
    st.markdown("<h2><i class='fa-solid fa-comments'></i> Assistant Virtuel</h2>", unsafe_allow_html=True)
    st.markdown("Posez-moi n'importe quelle question sur l'agriculture, vos cultures, ou les r√©sultats de vos analyses.")

    if not groq_client:
        st.warning("Veuillez configurer votre cl√© API Groq pour utiliser l'assistant virtuel.")
        st.info("Ajoutez `GROQ_API_KEY` dans les secrets de votre application Streamlit Cloud.")
        return

    with st.sidebar:
        if st.button("Effacer l'historique du Chat", use_container_width=True, key="clear_chat_button"):
            st.session_state.messages = [{"role": "bot", "content": "Bonjour ! Je suis votre assistant virtuel GreenField. Comment puis-je vous aider aujourd'hui ?"}]
            st.rerun()

    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "bot", "content": "Bonjour ! Je suis votre assistant virtuel GreenField. Comment puis-je vous aider aujourd'hui ?"}]

    for message in st.session_state.messages:
        with st.chat_message(message["role"], avatar='üßë‚Äçüåæ' if message["role"] == 'user' else 'ü§ñ'):
            st.markdown(message["content"])

    st.markdown("<div style='margin-top: 1.5rem;'></div>", unsafe_allow_html=True)

    with st.form("chat_input_form", clear_on_submit=True):
        message_input = st.text_input("üí¨ Entrez votre message ici :", "", key="chat_text_input", autocomplete="off")
        audio_file_uploader = st.file_uploader("üì¢ T√©l√©versez un message audio (format m4a, mp3, wav)", type=["m4a", "mp3", "wav"], key="chat_audio_uploader")
        send_button = st.form_submit_button("‚úâÔ∏è Envoyer Message", type="primary")

    processed_message_content = ""

    if send_button:
        if audio_file_uploader:
            st.info("Traitement du fichier audio t√©l√©vers√©...")
            filename = None
            try:
                filename = tempfile.NamedTemporaryFile(delete=False, suffix=f".{audio_file_uploader.name.split('.')[-1]}").name
                with open(filename, "wb") as f:
                    f.write(audio_file_uploader.getvalue())

                with open(filename, "rb") as file_to_transcribe:
                    with st.spinner("Transcription audio en cours..."):
                        transcription = groq_client.audio.transcriptions.create(
                            file=(audio_file_uploader.name, file_to_transcribe.read()),
                            model="whisper-large-v3",
                            response_format="json",
                            language="fr",
                            temperature=0.0
                        )
                processed_message_content = transcription.text
                st.session_state.messages.append({"role": "user", "content": processed_message_content})
            except Exception as e:
                st.error(f"Erreur Transcription (Fichier T√©l√©vers√©): Impossible de transcrire le fichier audio. V√©rifiez le format et votre cl√© API Groq. Erreur: {e}")
                processed_message_content = ""
            finally:
                if filename and os.path.exists(filename):
                    os.remove(filename)
        elif message_input:
            processed_message_content = message_input
            st.session_state.messages.append({"role": "user", "content": processed_message_content})

        if processed_message_content:
            with st.spinner("Le chatbot r√©fl√©chit..."):
                try:
                    chat_completion = groq_client.chat.completions.create(messages=[{"role": "user", "content": processed_message_content}], model="llama3-70b-8192")
                    response_text = chat_completion.choices[0].message.content
                    st.session_state.messages.append({"role": "bot", "content": response_text})

                except Exception as e:
                    st.error(f"Erreur Chatbot (API): Impossible d'obtenir une r√©ponse du chatbot Groq. Erreur: {e}")
                    st.session_state.messages.append({"role": "bot", "content": "D√©sol√©, je n'ai pas pu traiter votre demande. Une erreur est survenue lors de la communication avec le service de chatbot."})

        st.rerun()


# --- LOGIQUE PRINCIPALE DE L'APPLICATION ---

# Chargement du CSS et Font Awesome
load_css(CSS_PATH)
st.markdown("""<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">""", unsafe_allow_html=True)

# Initialisation du client Groq (gestion des erreurs et cl√©s)
groq_client = None
try:
    groq_api_key = st.secrets["GROQ_API_KEY"]
    if groq_api_key:
        groq_client = Groq(api_key=groq_api_key)
    else:
        st.sidebar.warning("GROQ_API_KEY non trouv√©e dans les secrets Streamlit Cloud. Le chatbot et les recommandations d'analyse ne seront pas disponibles.")
except KeyError:
    st.sidebar.warning("GROQ_API_KEY non configur√©e dans les secrets Streamlit Cloud. Le chatbot et les recommandations d'analyse ne seront pas disponibles.")
except Exception as e:
    st.sidebar.error(f"Erreur d'initialisation Groq : {e}. Le chatbot et les recommandations seront d√©sactiv√©s.")

# Chargement du mod√®le Keras (mise en cache automatique par @st.cache_resource)
keras_model = load_keras_model_from_hub(HF_MODEL_REPO_ID, HF_MODEL_FILENAME)

# Configuration de la barre lat√©rale
with st.sidebar:
    try:
        logo_image = Image.open(LOGO_PATH)
        st.image(logo_image, use_container_width=True)
    except FileNotFoundError:
        st.warning(f"Logo non trouv√© √† {LOGO_PATH}. L'image par d√©faut sera utilis√©e.")
    except Exception as e:
        st.warning(f"Erreur lors du chargement du logo : {e}")
    
    st.markdown("<h2 style='text-align: center;'>Menu Principal</h2>", unsafe_allow_html=True)
    
    if st.button("üìä Tableau de Bord", use_container_width=True, key="nav_dashboard"):
        st.session_state.current_view = "dashboard"
        st.rerun()
    
    if st.button("üå± Analyser ma plante", use_container_width=True, key="nav_analysis"):
        st.session_state.current_view = "plant_analysis"
        st.rerun()

    if st.button("üí¨ Assistant Virtuel", use_container_width=True, key="nav_chat"):
        st.session_state.current_view = "chat"
        st.rerun()

    st.markdown("<hr style='margin: 1.5rem 0;'>", unsafe_allow_html=True)

    if st.button("üö™ D√©connexion", use_container_width=True, key="nav_logout"):
        st.warning("D√©connexion simul√©e. Ajoutez votre logique de d√©connexion ici.")
        st.session_state.current_view = "dashboard"
        st.rerun()

    st.markdown("<div style='text-align: center; font-size: 0.8rem; color: var(--text-color-light); margin-top: 2rem;'>¬© 2025 GreenField Pro. Tous droits r√©serv√©s.</div>", unsafe_allow_html=True)


if "current_view" not in st.session_state:
    st.session_state.current_view = "dashboard"

if st.session_state.current_view == "dashboard":
    show_dashboard_view()
elif st.session_state.current_view == "plant_analysis":
    show_plant_analysis_view(groq_client, keras_model)
elif st.session_state.current_view == "chat":
    show_chatbot_view(groq_client)
else:
    show_dashboard_view()
